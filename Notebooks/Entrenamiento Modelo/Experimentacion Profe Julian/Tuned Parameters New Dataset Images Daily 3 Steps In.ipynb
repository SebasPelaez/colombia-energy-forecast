{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalar Dependencias "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En caso de que no se tengan instaladas estos paquetes, recomiendo instalarlos en las versiones a continuaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install boto3==1.16.59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Pillow==7.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras-tuner==1.0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import sys\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "sys.path.append('..')\n",
    "import CustomHyperModelImages\n",
    "import EnergyPricesLibrary as Ep\n",
    "\n",
    "from kerastuner.tuners import BayesianOptimization\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model,scaler_y,trainX,trainY,testX,testY,n_steps_out,len_output_features):\n",
    "    \n",
    "    # make predictions\n",
    "    trainPredict = model.predict(trainX)\n",
    "    trainPredict = trainPredict.reshape(trainPredict.shape[0]*n_steps_out,len_output_features)\n",
    "    testPredict  = model.predict(testX)\n",
    "    testPredict  = testPredict.reshape(testPredict.shape[0]*n_steps_out,len_output_features)\n",
    "    \n",
    "    # invert predictions\n",
    "    trainPredict = scaler_y.inverse_transform(trainPredict)\n",
    "    trainY_ = scaler_y.inverse_transform(trainY.reshape(trainY.shape[0]*n_steps_out,len_output_features))\n",
    "    \n",
    "    testPredict = scaler_y.inverse_transform(testPredict)\n",
    "    testY_ = scaler_y.inverse_transform(testY.reshape(testY.shape[0]*n_steps_out,len_output_features))\n",
    "        \n",
    "    return trainPredict,trainY_,testPredict,testY_\n",
    "\n",
    "def get_metrics(trainY,trainPredict,testY,testPredict):\n",
    "    \n",
    "    trainMAPE  = Ep.MAPE(trainPredict,trainY)\n",
    "    testMAPE  = Ep.MAPE(testPredict,testY)\n",
    "    \n",
    "    train_sMAPE  = Ep.sMAPE(trainY,trainPredict)\n",
    "    test_sMAPE  = Ep.sMAPE(testY,testPredict)\n",
    "    \n",
    "    return trainMAPE,testMAPE,train_sMAPE,test_sMAPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('dataset'):\n",
    "    s3_resource = boto3.resource('s3',\n",
    "                                 aws_access_key_id='AKIA4NVVYWBFHY2KRSMC',\n",
    "                                 aws_secret_access_key='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')\n",
    "    bucket = s3_resource.Bucket('colombia-energy-forecast')\n",
    "\n",
    "    for obj in bucket.objects.filter():\n",
    "        if not os.path.exists(os.path.dirname(obj.key)):\n",
    "            os.makedirs(os.path.dirname(obj.key))\n",
    "        if '.xlsx' in obj.key or '.jpg' in obj.key:\n",
    "            bucket.download_file(obj.key, obj.key) # save to same path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "climatic_images_prcp_dir = os.path.join('dataset','Climatic Images','PRCP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "climatic_images_tavg_dir = os.path.join('dataset','Climatic Images','TAVG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "precio_bolsa_path = os.path.join('dataset','Series','Sabanas','Original','Sabana_Datos_Precio_Bolsa.xlsx')\n",
    "precio_bolsa = pd.read_excel(precio_bolsa_path,engine='openpyxl')\n",
    "precio_bolsa = precio_bolsa.set_index('Fecha')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_fechas = list()\n",
    "lista_rutas = list()\n",
    "for prcp_file,tavg_file in zip(os.listdir(climatic_images_prcp_dir),os.listdir(climatic_images_tavg_dir)):\n",
    "    fecha = prcp_file.split('.')[0]\n",
    "    ruta_prcp = os.path.join(climatic_images_prcp_dir,prcp_file)\n",
    "    ruta_tavg = os.path.join(climatic_images_tavg_dir,tavg_file)\n",
    "    lista_fechas.append(fecha)\n",
    "    lista_rutas.append([ruta_prcp,ruta_tavg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 'All'\n",
    "start_date_train = '2000-02-01'\n",
    "start_date_val = '2020-01-01'\n",
    "start_date_test = '2020-04-01'\n",
    "end_date_test = '2020-05-01'\n",
    "n_steps_out=24\n",
    "output_columns = ['$kWh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = pd.DataFrame(lista_rutas,index=lista_fechas,columns=['Precipitacion','Temperatura'])\n",
    " \n",
    "n_steps_in  = 3\n",
    "overlap = 1\n",
    "len_output_features = len(output_columns)\n",
    "\n",
    "IMG_HEIGHT,IMG_WIDTH = 128,128\n",
    "\n",
    "results = Ep.SplitTimeseriesMultipleTimesBackAhead_DifferentTimes_Images(df_x=dataset_df,df_y=precio_bolsa,\n",
    "                                                                         start_date_train=start_date_train,\n",
    "                                                                         start_date_val=start_date_val,\n",
    "                                                                         start_date_test=start_date_test,\n",
    "                                                                         end_date_test=end_date_test,n_steps_out=n_steps_out,\n",
    "                                                                         n_steps_in=n_steps_in,overlap=overlap,\n",
    "                                                                         output_features=output_columns,\n",
    "                                                                         IMG_HEIGHT=IMG_HEIGHT,IMG_WIDTH=IMG_WIDTH)\n",
    "\n",
    "trainX_I,trainY_I,valX_I,valY_I,testX_I,testY_I,scaler_y_I,dataset_x_I,dataset_y_I = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Train:', (7271, 3, 128, 128, 6), (7271, 24, 1))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Train:',trainX_I.shape, trainY_I.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Val:', (91, 3, 128, 128, 6), (91, 24, 1))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Val:',valX_I.shape,valY_I.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Test:', (30, 3, 128, 128, 6), (30, 24, 1))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Test:',testX_I.shape, testY_I.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                                          factor=0.1,\n",
    "                                                          min_lr=1e-5,\n",
    "                                                          patience=5,\n",
    "                                                          verbose=1)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                  patience=10,\n",
    "                                                  mode='min')\n",
    "\n",
    "callbacks = [callback_reduce_lr,early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = trainX_I[0].shape\n",
    "\n",
    "arquitectura1 = CustomHyperModelImages.ArquitecturaI1(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)\n",
    "arquitectura2 = CustomHyperModelImages.ArquitecturaI2(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)\n",
    "arquitectura3 = CustomHyperModelImages.ArquitecturaI3(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)\n",
    "arquitectura4 = CustomHyperModelImages.ArquitecturaI4(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)\n",
    "arquitectura5 = CustomHyperModelImages.ArquitecturaI5(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)\n",
    "arquitectura6 = CustomHyperModelImages.ArquitecturaI6(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)\n",
    "arquitectura7 = CustomHyperModelImages.ArquitecturaI7(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)\n",
    "arquitectura8 = CustomHyperModelImages.ArquitecturaI8(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)\n",
    "arquitectura9 = CustomHyperModelImages.ArquitecturaI9(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)\n",
    "arquitectura10 = CustomHyperModelImages.ArquitecturaI10(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)\n",
    "arquitectura11 = CustomHyperModelImages.ArquitecturaI11(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)\n",
    "arquitectura12 = CustomHyperModelImages.ArquitecturaI12(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "arq_list = [arquitectura1,arquitectura2,arquitectura3,arquitectura4,\n",
    "            arquitectura5,arquitectura6,arquitectura7,arquitectura8,\n",
    "            arquitectura9,arquitectura10,arquitectura11,arquitectura12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 51s]\n",
      "val_loss: 4894.16162109375\n",
      "\n",
      "Best val_loss So Far: 3145.473876953125\n",
      "Total elapsed time: 00h 14m 34s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Tiempo Total Transcurrido 874.3904240131378\n"
     ]
    }
   ],
   "source": [
    "arq_idx = 1\n",
    "arq_best_models = dict()\n",
    "\n",
    "for arq in arq_list:\n",
    "    \n",
    "    bayesian_tuner = BayesianOptimization(\n",
    "        arq,\n",
    "        objective='val_loss',\n",
    "        num_initial_points=1,\n",
    "        max_trials=10,\n",
    "        directory='dir_images_3',\n",
    "        project_name=str(arq_idx)\n",
    "    )\n",
    "    \n",
    "    # Overview of the task\n",
    "    bayesian_tuner.search_space_summary()\n",
    "    \n",
    "    # Performs the hyperparameter tuning\n",
    "    search_start = time.time()\n",
    "    bayesian_tuner.search(x=trainX_I,y=trainY_I,\n",
    "                      epochs=200,\n",
    "                      validation_data=(valX_I,valY_I),\n",
    "                      callbacks=callbacks)\n",
    "    search_end = time.time()\n",
    "    elapsed_time = search_end - search_start\n",
    "    \n",
    "    print('Tiempo Total Transcurrido {}'.format(elapsed_time))\n",
    "    \n",
    "    dict_key = 'Arquitectura {}'.format(arq_idx)\n",
    "\n",
    "    arq_best_models[dict_key] = dict()\n",
    "    bs_model = bayesian_tuner.oracle.get_best_trials(1)[0]\n",
    "    \n",
    "    model = bayesian_tuner.get_best_models(num_models=1)[0]\n",
    "    \n",
    "    trainPredict,trainY_true,testPredict,testY_true = make_predictions(model,scaler_y_I,trainX_I,trainY_I,valX_I,valY_I,\n",
    "                                                             n_steps_out,len_output_features)\n",
    "    \n",
    "    trainMAPE,testMAPE,train_sMAPE,test_sMAPE = get_metrics(trainY_true,trainPredict,testY_true,testPredict)\n",
    "\n",
    "    arq_best_models[dict_key]['Score'] = bs_model.score\n",
    "    arq_best_models[dict_key]['Tiempo Scaneo'] = elapsed_time\n",
    "    arq_best_models[dict_key]['Mape Train'] = trainMAPE\n",
    "    arq_best_models[dict_key]['Mape Test'] = testMAPE\n",
    "    arq_best_models[dict_key]['sMape Train'] = train_sMAPE\n",
    "    arq_best_models[dict_key]['sMape Test'] = test_sMAPE\n",
    "\n",
    "    if bs_model.hyperparameters.values:\n",
    "        for hp, value in bs_model.hyperparameters.values.items():\n",
    "            arq_best_models[dict_key][hp] = value\n",
    "    \n",
    "    arq_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('BestModels-Images-I3.json', 'w') as outfile:\n",
    "    json.dump(arq_best_models, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Arquitectura 1': {'Score': 2670.687744140625,\n",
       "  'Tiempo Scaneo': 3930.1997940540314,\n",
       "  'Mape Train': 2.299719611640904,\n",
       "  'Mape Test': 1.021646092923929,\n",
       "  'sMape Train': 74.16011225126769,\n",
       "  'sMape Test': 103.83206129277364,\n",
       "  'convLSTM2d_filters_layer_1': 8,\n",
       "  'convLSTM2d_kernel_layer_1': 3,\n",
       "  'conv2d_padding_layer_1': 'valid',\n",
       "  'convLSTM2d_filters_layer_3': 8,\n",
       "  'convLSTM2d_kernel_layer_3': 5,\n",
       "  'conv2d_padding_layer_3': 'valid',\n",
       "  'convLSTM2d_filters_layer_5': 8,\n",
       "  'convLSTM2d_kernel_layer_5': 5,\n",
       "  'conv2d_padding_layer_5': 'same',\n",
       "  'pool2d_size_layer_6': 5,\n",
       "  'dense_units_layer_8': 24,\n",
       "  'dense_layer_activation': 'relu',\n",
       "  'learning_rate': 0.01},\n",
       " 'Arquitectura 2': {'Score': 3029.8193359375,\n",
       "  'Tiempo Scaneo': 3477.373846769333,\n",
       "  'Mape Train': 0.6300291092061623,\n",
       "  'Mape Test': 0.7364700611650522,\n",
       "  'sMape Train': 55.47676949794128,\n",
       "  'sMape Test': 115.06071767587953,\n",
       "  'convLSTM2d_filters_layer_1': 8,\n",
       "  'convLSTM2d_kernel_layer_1': 3,\n",
       "  'conv2d_padding_layer_1': 'valid',\n",
       "  'pool2d_size_layer_2': 3,\n",
       "  'convLSTM2d_filters_layer_3': 8,\n",
       "  'convLSTM2d_kernel_layer_3': 3,\n",
       "  'conv2d_padding_layer_3': 'valid',\n",
       "  'pool2d_size_layer_4': 3,\n",
       "  'dense_units_layer_6': 120,\n",
       "  'dense_layer_6_activation': 'relu',\n",
       "  'learning_rate': 0.000785254666899134},\n",
       " 'Arquitectura 3': {'Score': 3182.7451171875,\n",
       "  'Tiempo Scaneo': 2413.799530982971,\n",
       "  'Mape Train': 0.7837751572104564,\n",
       "  'Mape Test': 0.8022868215926865,\n",
       "  'sMape Train': 67.72346626816777,\n",
       "  'sMape Test': 122.62688579456393,\n",
       "  'convLSTM2d_filters_layer_1': 8,\n",
       "  'convLSTM2d_kernel_layer_1': 5,\n",
       "  'conv2d_padding_layer_1': 'valid',\n",
       "  'pool2d_size_layer_2': 5,\n",
       "  'dense_units_layer_4': 48,\n",
       "  'dense_layer_4_activation': 'relu',\n",
       "  'learning_rate': 0.00035486849463869886},\n",
       " 'Arquitectura 4': {'Score': 2987.813232421875,\n",
       "  'Tiempo Scaneo': 3086.0255246162415,\n",
       "  'Mape Train': 0.6279170817437548,\n",
       "  'Mape Test': 0.7244549529311142,\n",
       "  'sMape Train': 56.00805669911764,\n",
       "  'sMape Test': 113.57886511707551,\n",
       "  'convLSTM2d_filters_layer_1': 8,\n",
       "  'convLSTM2d_kernel_layer_1': 5,\n",
       "  'conv2d_padding_layer_1': 'same',\n",
       "  'convLSTM2d_filters_layer_3': 8,\n",
       "  'convLSTM2d_kernel_layer_3': 5,\n",
       "  'conv2d_padding_layer_3': 'same',\n",
       "  'convLSTM2d_filters_layer_5': 8,\n",
       "  'convLSTM2d_kernel_layer_5': 3,\n",
       "  'conv2d_padding_layer_5': 'same',\n",
       "  'pool2d_size_layer_6': 3,\n",
       "  'learning_rate': 0.0022678489768469218},\n",
       " 'Arquitectura 5': {'Score': 2757.351318359375,\n",
       "  'Tiempo Scaneo': 3331.044022321701,\n",
       "  'Mape Train': 0.6153225057790224,\n",
       "  'Mape Test': 0.6802486328582924,\n",
       "  'sMape Train': 50.582227180910806,\n",
       "  'sMape Test': 104.34377528567472,\n",
       "  'convLSTM2d_filters_layer_1': 8,\n",
       "  'convLSTM2d_kernel_layer_1': 5,\n",
       "  'conv2d_padding_layer_1': 'valid',\n",
       "  'pool2d_size_layer_2': 3,\n",
       "  'convLSTM2d_filters_layer_3': 8,\n",
       "  'convLSTM2d_kernel_layer_3': 7,\n",
       "  'conv2d_padding_layer_3': 'same',\n",
       "  'pool2d_size_layer_4': 5,\n",
       "  'learning_rate': 0.0007628691814083777},\n",
       " 'Arquitectura 6': {'Score': 2761.840576171875,\n",
       "  'Tiempo Scaneo': 2736.7573215961456,\n",
       "  'Mape Train': 1.5487057700018574,\n",
       "  'Mape Test': 0.9206401751493198,\n",
       "  'sMape Train': 65.66702600586075,\n",
       "  'sMape Test': 106.22001669614922,\n",
       "  'convLSTM2d_filters_layer_1': 8,\n",
       "  'convLSTM2d_kernel_layer_1': 3,\n",
       "  'conv2d_padding_layer_1': 'same',\n",
       "  'pool2d_size_layer_2': 7,\n",
       "  'learning_rate': 0.0001},\n",
       " 'Arquitectura 7': {'Score': 2913.39111328125,\n",
       "  'Tiempo Scaneo': 1589.2898514270782,\n",
       "  'Mape Train': 0.59091354526759,\n",
       "  'Mape Test': 0.7000429703481719,\n",
       "  'sMape Train': 50.045849079138925,\n",
       "  'sMape Test': 108.9734174309456,\n",
       "  'conv2d_filters_layer_1': 8,\n",
       "  'conv2d_kernel_layer_1': 3,\n",
       "  'conv2d_padding_layer_1': 'valid',\n",
       "  'conv2d_filters_layer_3': 8,\n",
       "  'conv2d_kernel_layer_3': 5,\n",
       "  'conv2d_padding_layer_3': 'valid',\n",
       "  'conv2d_filters_layer_5': 8,\n",
       "  'conv2d_kernel_layer_5': 3,\n",
       "  'conv2d_padding_layer_5': 'valid',\n",
       "  'pool_kernel_layer_6': 3,\n",
       "  'lstm_units_layer_7': 448,\n",
       "  'kernel_regularizer_layer_7': 0.09,\n",
       "  'dropout_regularizer_layer_7': 0.09,\n",
       "  'dense_units_layer_8': 48,\n",
       "  'dense_layer_8_activation': 'tanh',\n",
       "  'learning_rate': 0.0009450190380457355},\n",
       " 'Arquitectura 8': {'Score': 3045.99755859375,\n",
       "  'Tiempo Scaneo': 951.941349029541,\n",
       "  'Mape Train': 0.5314234713217377,\n",
       "  'Mape Test': 0.7218471176048139,\n",
       "  'sMape Train': 48.95228475983844,\n",
       "  'sMape Test': 114.2473431807328,\n",
       "  'conv2d_filters_layer_1': 8,\n",
       "  'conv2d_kernel_layer_1': 5,\n",
       "  'conv2d_padding_layer_1': 'valid',\n",
       "  'pool_kernel_layer_2': 5,\n",
       "  'conv2d_filters_layer_3': 8,\n",
       "  'conv2d_kernel_layer_3': 5,\n",
       "  'conv2d_padding_layer_3': 'valid',\n",
       "  'pool_kernel_layer_4': 5,\n",
       "  'lstm_units_layer_6': 448,\n",
       "  'kernel_regularizer_layer_6': 0.0975,\n",
       "  'dropout_regularizer_layer_6': 0.44999999999999996,\n",
       "  'dense_units_layer_7': 72,\n",
       "  'dense_layer_7_activation': 'tanh',\n",
       "  'learning_rate': 0.00029522754062154114},\n",
       " 'Arquitectura 9': {'Score': 3258.846435546875,\n",
       "  'Tiempo Scaneo': 1153.7302186489105,\n",
       "  'Mape Train': 7.797336593776404,\n",
       "  'Mape Test': 2.397375372930376,\n",
       "  'sMape Train': 104.57851147460673,\n",
       "  'sMape Test': 125.37555807346497,\n",
       "  'conv2d_filters_layer_1': 8,\n",
       "  'conv2d_kernel_layer_1': 7,\n",
       "  'conv2d_padding_layer_1': 'valid',\n",
       "  'pool_kernel_layer_2': 5,\n",
       "  'lstm_units_layer_3': 384,\n",
       "  'kernel_regularizer_layer_4': 0.075,\n",
       "  'dropout_regularizer_layer_4': 0.8999999999999999,\n",
       "  'dense_units_layer_5': 72,\n",
       "  'dense_layer_5_activation': 'sigmoid',\n",
       "  'learning_rate': 0.00021816106513073495},\n",
       " 'Arquitectura 10': {'Score': 2913.6357421875,\n",
       "  'Tiempo Scaneo': 627.5136122703552,\n",
       "  'Mape Train': 0.5774021572766126,\n",
       "  'Mape Test': 0.7022811592113561,\n",
       "  'sMape Train': 49.75653915464945,\n",
       "  'sMape Test': 109.56440478010948,\n",
       "  'conv2d_filters_layer_1': 8,\n",
       "  'conv2d_kernel_layer_1': 3,\n",
       "  'conv2d_padding_layer_1': 'valid',\n",
       "  'conv2d_filters_layer_3': 8,\n",
       "  'conv2d_kernel_layer_3': 5,\n",
       "  'conv2d_padding_layer_3': 'valid',\n",
       "  'conv2d_filters_layer_5': 8,\n",
       "  'conv2d_kernel_layer_5': 5,\n",
       "  'conv2d_padding_layer_5': 'valid',\n",
       "  'pool_kernel_layer_6': 3,\n",
       "  'lstm_units_layer_7': 384,\n",
       "  'kernel_regularizer_layer_7': 0.08249999999999999,\n",
       "  'dropout_regularizer_layer_7': 0.44999999999999996,\n",
       "  'learning_rate': 0.0003236237786822184},\n",
       " 'Arquitectura 11': {'Score': 2846.03564453125,\n",
       "  'Tiempo Scaneo': 1278.5485656261444,\n",
       "  'Mape Train': 0.9474671958558587,\n",
       "  'Mape Test': 0.645513535851528,\n",
       "  'sMape Train': 59.59655980759242,\n",
       "  'sMape Test': 101.50692837731604,\n",
       "  'conv2d_filters_layer_1': 8,\n",
       "  'conv2d_kernel_layer_1': 3,\n",
       "  'conv2d_padding_layer_1': 'same',\n",
       "  'pool_kernel_layer_2': 5,\n",
       "  'conv2d_filters_layer_3': 8,\n",
       "  'conv2d_kernel_layer_3': 7,\n",
       "  'conv2d_padding_layer_3': 'valid',\n",
       "  'pool_kernel_layer_4': 3,\n",
       "  'lstm_units_layer_6': 256,\n",
       "  'kernel_regularizer_layer_6': 0.0675,\n",
       "  'dropout_regularizer_layer_6': 0.27,\n",
       "  'learning_rate': 0.0026441881890449143},\n",
       " 'Arquitectura 12': {'Score': 3145.473876953125,\n",
       "  'Tiempo Scaneo': 874.3904240131378,\n",
       "  'Mape Train': 0.5357431100560549,\n",
       "  'Mape Test': 0.7373080870874831,\n",
       "  'sMape Train': 53.941126725251166,\n",
       "  'sMape Test': 118.72578988348954,\n",
       "  'conv2d_filters_layer_1': 8,\n",
       "  'conv2d_kernel_layer_1': 5,\n",
       "  'conv2d_padding_layer_1': 'valid',\n",
       "  'pool_kernel_layer_2': 7,\n",
       "  'lstm_units_layer_3': 64,\n",
       "  'kernel_regularizer_layer_4': 0.075,\n",
       "  'dropout_regularizer_layer_4': 0.36,\n",
       "  'learning_rate': 0.00041670437570096735}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arq_best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Proyecto Grados",
   "language": "python",
   "name": "proyecto-grados"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
