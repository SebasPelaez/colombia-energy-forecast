{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalar Dependencias "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En caso de que no se tengan instaladas estos paquetes, recomiendo instalarlos en las versiones a continuaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3==1.16.59 in /home/julian/anaconda3/lib/python3.7/site-packages (1.16.59)\r\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /home/julian/.local/lib/python3.7/site-packages (from boto3==1.16.59) (0.3.3)\r\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/julian/.local/lib/python3.7/site-packages (from boto3==1.16.59) (0.9.5)\r\n",
      "Requirement already satisfied: botocore<1.20.0,>=1.19.59 in /home/julian/anaconda3/lib/python3.7/site-packages (from boto3==1.16.59) (1.19.63)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/julian/anaconda3/lib/python3.7/site-packages (from botocore<1.20.0,>=1.19.59->boto3==1.16.59) (1.25.11)\r\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/julian/.local/lib/python3.7/site-packages (from botocore<1.20.0,>=1.19.59->boto3==1.16.59) (2.8.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/julian/anaconda3/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.20.0,>=1.19.59->boto3==1.16.59) (1.15.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3==1.16.59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Pillow==7.2.0\n",
      "  Using cached Pillow-7.2.0-cp37-cp37m-manylinux1_x86_64.whl (2.2 MB)\n",
      "Installing collected packages: Pillow\n",
      "  Attempting uninstall: Pillow\n",
      "    Found existing installation: Pillow 8.1.0\n",
      "    Uninstalling Pillow-8.1.0:\n",
      "      Successfully uninstalled Pillow-8.1.0\n",
      "Successfully installed Pillow-7.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install Pillow==7.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-tuner==1.0.2 in /home/julian/anaconda3/lib/python3.7/site-packages (1.0.2)\r\n",
      "Requirement already satisfied: scipy in /home/julian/.local/lib/python3.7/site-packages (from keras-tuner==1.0.2) (1.4.1)\r\n",
      "Requirement already satisfied: future in /home/julian/.local/lib/python3.7/site-packages (from keras-tuner==1.0.2) (0.18.2)\r\n",
      "Requirement already satisfied: requests in /home/julian/anaconda3/lib/python3.7/site-packages (from keras-tuner==1.0.2) (2.22.0)\r\n",
      "Requirement already satisfied: terminaltables in /home/julian/anaconda3/lib/python3.7/site-packages (from keras-tuner==1.0.2) (3.1.0)\r\n",
      "Requirement already satisfied: colorama in /home/julian/anaconda3/lib/python3.7/site-packages (from keras-tuner==1.0.2) (0.4.4)\r\n",
      "Requirement already satisfied: scikit-learn in /home/julian/anaconda3/lib/python3.7/site-packages (from keras-tuner==1.0.2) (0.22.1)\r\n",
      "Requirement already satisfied: tqdm in /home/julian/anaconda3/lib/python3.7/site-packages (from keras-tuner==1.0.2) (4.56.0)\r\n",
      "Requirement already satisfied: tabulate in /home/julian/anaconda3/lib/python3.7/site-packages (from keras-tuner==1.0.2) (0.8.7)\r\n",
      "Requirement already satisfied: numpy in /home/julian/anaconda3/lib/python3.7/site-packages (from keras-tuner==1.0.2) (1.19.5)\r\n",
      "Requirement already satisfied: packaging in /home/julian/anaconda3/lib/python3.7/site-packages (from keras-tuner==1.0.2) (20.9)\r\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/julian/.local/lib/python3.7/site-packages (from packaging->keras-tuner==1.0.2) (2.4.6)\r\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/julian/anaconda3/lib/python3.7/site-packages (from requests->keras-tuner==1.0.2) (2.8)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/julian/anaconda3/lib/python3.7/site-packages (from requests->keras-tuner==1.0.2) (2020.12.5)\r\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/julian/anaconda3/lib/python3.7/site-packages (from requests->keras-tuner==1.0.2) (3.0.4)\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/julian/anaconda3/lib/python3.7/site-packages (from requests->keras-tuner==1.0.2) (1.25.11)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /home/julian/.local/lib/python3.7/site-packages (from scikit-learn->keras-tuner==1.0.2) (0.14.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-tuner==1.0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import sys\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "sys.path.append('..')\n",
    "import CustomHyperModelImages\n",
    "import EnergyPricesLibrary as Ep\n",
    "\n",
    "from kerastuner.tuners import BayesianOptimization\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model,scaler_y,trainX,trainY,testX,testY,n_steps_out,len_output_features):\n",
    "    \n",
    "    # make predictions\n",
    "    trainPredict = model.predict(trainX)\n",
    "    trainPredict = trainPredict.reshape(trainPredict.shape[0]*n_steps_out,len_output_features)\n",
    "    testPredict  = model.predict(testX)\n",
    "    testPredict  = testPredict.reshape(testPredict.shape[0]*n_steps_out,len_output_features)\n",
    "    \n",
    "    # invert predictions\n",
    "    trainPredict = scaler_y.inverse_transform(trainPredict)\n",
    "    trainY_ = scaler_y.inverse_transform(trainY.reshape(trainY.shape[0]*n_steps_out,len_output_features))\n",
    "    \n",
    "    testPredict = scaler_y.inverse_transform(testPredict)\n",
    "    testY_ = scaler_y.inverse_transform(testY.reshape(testY.shape[0]*n_steps_out,len_output_features))\n",
    "        \n",
    "    return trainPredict,trainY_,testPredict,testY_\n",
    "\n",
    "def get_metrics(trainY,trainPredict,testY,testPredict):\n",
    "    \n",
    "    trainMAPE  = Ep.MAPE(trainPredict,trainY)\n",
    "    testMAPE  = Ep.MAPE(testPredict,testY)\n",
    "    \n",
    "    train_sMAPE  = Ep.sMAPE(trainY,trainPredict)\n",
    "    test_sMAPE  = Ep.sMAPE(testY,testPredict)\n",
    "    \n",
    "    return trainMAPE,testMAPE,train_sMAPE,test_sMAPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('dataset'):\n",
    "    s3_resource = boto3.resource('s3',\n",
    "                                 aws_access_key_id='AKIA4NVVYWBFHY2KRSMC',\n",
    "                                 aws_secret_access_key='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')\n",
    "    bucket = s3_resource.Bucket('colombia-energy-forecast')\n",
    "\n",
    "    for obj in bucket.objects.filter():\n",
    "        if not os.path.exists(os.path.dirname(obj.key)):\n",
    "            os.makedirs(os.path.dirname(obj.key))\n",
    "        if '.xlsx' in obj.key or '.jpg' in obj.key:\n",
    "            bucket.download_file(obj.key, obj.key) # save to same path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "climatic_images_prcp_dir = os.path.join('dataset','Climatic Images','PRCP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "climatic_images_tavg_dir = os.path.join('dataset','Climatic Images','TAVG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /home/julian/anaconda3/lib/python3.7/site-packages (3.0.6)\r\n",
      "Requirement already satisfied: jdcal in /home/julian/anaconda3/lib/python3.7/site-packages (from openpyxl) (1.4.1)\r\n",
      "Requirement already satisfied: et-xmlfile in /home/julian/anaconda3/lib/python3.7/site-packages (from openpyxl) (1.0.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "precio_bolsa_path = os.path.join('dataset','Series','Sabanas','Original','Sabana_Datos_Precio_Bolsa.xlsx')\n",
    "precio_bolsa = pd.read_excel(precio_bolsa_path,engine='openpyxl')\n",
    "precio_bolsa = precio_bolsa.set_index('Fecha')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_fechas = list()\n",
    "lista_rutas = list()\n",
    "for prcp_file,tavg_file in zip(os.listdir(climatic_images_prcp_dir),os.listdir(climatic_images_tavg_dir)):\n",
    "    fecha = prcp_file.split('.')[0]\n",
    "    ruta_prcp = os.path.join(climatic_images_prcp_dir,prcp_file)\n",
    "    ruta_tavg = os.path.join(climatic_images_tavg_dir,tavg_file)\n",
    "    lista_fechas.append(fecha)\n",
    "    lista_rutas.append([ruta_prcp,ruta_tavg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 'All'\n",
    "start_date_train = '2000-02-01'\n",
    "start_date_val = '2020-01-01'\n",
    "start_date_test = '2020-04-01'\n",
    "end_date_test = '2020-05-01'\n",
    "n_steps_out=24\n",
    "output_columns = ['$kWh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = pd.DataFrame(lista_rutas,index=lista_fechas,columns=['Precipitacion','Temperatura'])\n",
    " \n",
    "n_steps_in  = 2\n",
    "overlap = 1\n",
    "len_output_features = len(output_columns)\n",
    "\n",
    "IMG_HEIGHT,IMG_WIDTH = 128,128\n",
    "\n",
    "results = Ep.SplitTimeseriesMultipleTimesBackAhead_DifferentTimes_Images(df_x=dataset_df,df_y=precio_bolsa,\n",
    "                                                                         start_date_train=start_date_train,\n",
    "                                                                         start_date_val=start_date_val,\n",
    "                                                                         start_date_test=start_date_test,\n",
    "                                                                         end_date_test=end_date_test,n_steps_out=n_steps_out,\n",
    "                                                                         n_steps_in=n_steps_in,overlap=overlap,\n",
    "                                                                         output_features=output_columns,\n",
    "                                                                         IMG_HEIGHT=IMG_HEIGHT,IMG_WIDTH=IMG_WIDTH)\n",
    "\n",
    "trainX_I,trainY_I,valX_I,valY_I,testX_I,testY_I,scaler_y_I,dataset_x_I,dataset_y_I = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Train:', (7272, 2, 128, 128, 6), (7272, 24, 1))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Train:',trainX_I.shape, trainY_I.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Val:', (91, 2, 128, 128, 6), (91, 24, 1))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Val:',valX_I.shape,valY_I.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Test:', (30, 2, 128, 128, 6), (30, 24, 1))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Test:',testX_I.shape, testY_I.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                                          factor=0.1,\n",
    "                                                          min_lr=1e-5,\n",
    "                                                          patience=5,\n",
    "                                                          verbose=1)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                  patience=10,\n",
    "                                                  mode='min')\n",
    "\n",
    "callbacks = [callback_reduce_lr,early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = trainX_I[0].shape\n",
    "\n",
    "arquitectura1 = CustomHyperModelImages.ArquitecturaI1(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)\n",
    "arquitectura2 = CustomHyperModelImages.ArquitecturaI2(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)\n",
    "arquitectura3 = CustomHyperModelImages.ArquitecturaI3(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)\n",
    "arquitectura4 = CustomHyperModelImages.ArquitecturaI4(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)\n",
    "arquitectura5 = CustomHyperModelImages.ArquitecturaI5(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)\n",
    "arquitectura6 = CustomHyperModelImages.ArquitecturaI6(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)\n",
    "arquitectura7 = CustomHyperModelImages.ArquitecturaI7(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)\n",
    "arquitectura8 = CustomHyperModelImages.ArquitecturaI8(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)\n",
    "arquitectura9 = CustomHyperModelImages.ArquitecturaI9(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)\n",
    "arquitectura10 = CustomHyperModelImages.ArquitecturaI10(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)\n",
    "arquitectura11 = CustomHyperModelImages.ArquitecturaI11(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)\n",
    "arquitectura12 = CustomHyperModelImages.ArquitecturaI12(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "arq_list = [arquitectura1,arquitectura2,arquitectura3,arquitectura4,\n",
    "            arquitectura5,arquitectura6,arquitectura7,arquitectura8,\n",
    "            arquitectura9,arquitectura10,arquitectura11,arquitectura12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 02m 05s]\n",
      "val_loss: 1636.8990478515625\n",
      "\n",
      "Best val_loss So Far: 1607.894287109375\n",
      "Total elapsed time: 00h 18m 10s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Tiempo Total Transcurrido 1090.521910905838\n"
     ]
    }
   ],
   "source": [
    "arq_idx = 1\n",
    "arq_best_models = dict()\n",
    "\n",
    "for arq in arq_list:\n",
    "    \n",
    "    bayesian_tuner = BayesianOptimization(\n",
    "        arq,\n",
    "        objective='val_loss',\n",
    "        num_initial_points=1,\n",
    "        max_trials=10,\n",
    "        directory='dir_images_2',\n",
    "        project_name=str(arq_idx)\n",
    "    )\n",
    "    \n",
    "    # Overview of the task\n",
    "    bayesian_tuner.search_space_summary()\n",
    "    \n",
    "    # Performs the hyperparameter tuning\n",
    "    search_start = time.time()\n",
    "    bayesian_tuner.search(x=trainX_I,y=trainY_I,\n",
    "                      epochs=200,\n",
    "                      validation_data=(valX_I,valY_I),\n",
    "                      callbacks=callbacks)\n",
    "    search_end = time.time()\n",
    "    elapsed_time = search_end - search_start\n",
    "    \n",
    "    print('Tiempo Total Transcurrido {}'.format(elapsed_time))\n",
    "    \n",
    "    dict_key = 'Arquitectura {}'.format(arq_idx)\n",
    "\n",
    "    arq_best_models[dict_key] = dict()\n",
    "    bs_model = bayesian_tuner.oracle.get_best_trials(1)[0]\n",
    "    \n",
    "    model = bayesian_tuner.get_best_models(num_models=1)[0]\n",
    "    \n",
    "    trainPredict,trainY_true,testPredict,testY_true = make_predictions(model,scaler_y_I,trainX_I,trainY_I,valX_I,valY_I,\n",
    "                                                             n_steps_out,len_output_features)\n",
    "    \n",
    "    trainMAPE,testMAPE,train_sMAPE,test_sMAPE = get_metrics(trainY_true,trainPredict,testY_true,testPredict)\n",
    "\n",
    "    arq_best_models[dict_key]['Score'] = bs_model.score\n",
    "    arq_best_models[dict_key]['Tiempo Scaneo'] = elapsed_time\n",
    "    arq_best_models[dict_key]['Mape Train'] = trainMAPE\n",
    "    arq_best_models[dict_key]['Mape Test'] = testMAPE\n",
    "    arq_best_models[dict_key]['sMape Train'] = train_sMAPE\n",
    "    arq_best_models[dict_key]['sMape Test'] = test_sMAPE\n",
    "\n",
    "    if bs_model.hyperparameters.values:\n",
    "        for hp, value in bs_model.hyperparameters.values.items():\n",
    "            arq_best_models[dict_key][hp] = value\n",
    "    \n",
    "    arq_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('BestModels-Images-I2.json', 'w') as outfile:\n",
    "    json.dump(arq_best_models, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Arquitectura 1': {'Score': 2622.885498046875,\n",
       "  'Tiempo Scaneo': 2635.663916349411,\n",
       "  'Mape Train': 0.838784229630798,\n",
       "  'Mape Test': 0.6618041342002662,\n",
       "  'sMape Train': 61.97091603972493,\n",
       "  'sMape Test': 100.00572811670833,\n",
       "  'convLSTM2d_filters_layer_1': 8,\n",
       "  'convLSTM2d_kernel_layer_1': 3,\n",
       "  'conv2d_padding_layer_1': 'same',\n",
       "  'convLSTM2d_filters_layer_3': 8,\n",
       "  'convLSTM2d_kernel_layer_3': 3,\n",
       "  'conv2d_padding_layer_3': 'same',\n",
       "  'convLSTM2d_filters_layer_5': 8,\n",
       "  'convLSTM2d_kernel_layer_5': 5,\n",
       "  'conv2d_padding_layer_5': 'same',\n",
       "  'pool2d_size_layer_6': 5,\n",
       "  'dense_units_layer_8': 120,\n",
       "  'dense_layer_activation': 'relu',\n",
       "  'learning_rate': 0.01},\n",
       " 'Arquitectura 2': {'Score': 2994.450439453125,\n",
       "  'Tiempo Scaneo': 2264.076488018036,\n",
       "  'Mape Train': 0.6357002314678698,\n",
       "  'Mape Test': 0.7270164239702169,\n",
       "  'sMape Train': 56.06393628320085,\n",
       "  'sMape Test': 113.79858410903397,\n",
       "  'convLSTM2d_filters_layer_1': 8,\n",
       "  'convLSTM2d_kernel_layer_1': 5,\n",
       "  'conv2d_padding_layer_1': 'valid',\n",
       "  'pool2d_size_layer_2': 5,\n",
       "  'convLSTM2d_filters_layer_3': 8,\n",
       "  'convLSTM2d_kernel_layer_3': 5,\n",
       "  'conv2d_padding_layer_3': 'valid',\n",
       "  'pool2d_size_layer_4': 5,\n",
       "  'dense_units_layer_6': 96,\n",
       "  'dense_layer_6_activation': 'tanh',\n",
       "  'learning_rate': 0.0009265876607401646},\n",
       " 'Arquitectura 3': {'Score': 3167.57958984375,\n",
       "  'Tiempo Scaneo': 1541.2203154563904,\n",
       "  'Mape Train': 0.5961335748654453,\n",
       "  'Mape Test': 0.7518702591265449,\n",
       "  'sMape Train': 61.48749490739907,\n",
       "  'sMape Test': 120.97508458535808,\n",
       "  'convLSTM2d_filters_layer_1': 8,\n",
       "  'convLSTM2d_kernel_layer_1': 7,\n",
       "  'conv2d_padding_layer_1': 'same',\n",
       "  'pool2d_size_layer_2': 7,\n",
       "  'dense_units_layer_4': 72,\n",
       "  'dense_layer_4_activation': 'tanh',\n",
       "  'learning_rate': 0.0001747261213347036},\n",
       " 'Arquitectura 4': {'Score': 2173.91064453125,\n",
       "  'Tiempo Scaneo': 2363.783674955368,\n",
       "  'Mape Train': 0.9514651372633859,\n",
       "  'Mape Test': 0.5798619273219725,\n",
       "  'sMape Train': 59.10915777376511,\n",
       "  'sMape Test': 82.91042606409782,\n",
       "  'convLSTM2d_filters_layer_1': 8,\n",
       "  'convLSTM2d_kernel_layer_1': 3,\n",
       "  'conv2d_padding_layer_1': 'same',\n",
       "  'convLSTM2d_filters_layer_3': 8,\n",
       "  'convLSTM2d_kernel_layer_3': 3,\n",
       "  'conv2d_padding_layer_3': 'valid',\n",
       "  'convLSTM2d_filters_layer_5': 8,\n",
       "  'convLSTM2d_kernel_layer_5': 3,\n",
       "  'conv2d_padding_layer_5': 'same',\n",
       "  'pool2d_size_layer_6': 5,\n",
       "  'learning_rate': 0.01},\n",
       " 'Arquitectura 5': {'Score': 3079.70263671875,\n",
       "  'Tiempo Scaneo': 1901.7561655044556,\n",
       "  'Mape Train': 0.5743351580258225,\n",
       "  'Mape Test': 0.7360880476661996,\n",
       "  'sMape Train': 55.109507037312795,\n",
       "  'sMape Test': 116.85288927804582,\n",
       "  'convLSTM2d_filters_layer_1': 8,\n",
       "  'convLSTM2d_kernel_layer_1': 5,\n",
       "  'conv2d_padding_layer_1': 'same',\n",
       "  'pool2d_size_layer_2': 3,\n",
       "  'convLSTM2d_filters_layer_3': 8,\n",
       "  'convLSTM2d_kernel_layer_3': 7,\n",
       "  'conv2d_padding_layer_3': 'same',\n",
       "  'pool2d_size_layer_4': 3,\n",
       "  'learning_rate': 0.00030867483852904887},\n",
       " 'Arquitectura 6': {'Score': 3066.13330078125,\n",
       "  'Tiempo Scaneo': 1587.7528352737427,\n",
       "  'Mape Train': 0.9073351769647133,\n",
       "  'Mape Test': 0.7969831908774765,\n",
       "  'sMape Train': 62.00436709575448,\n",
       "  'sMape Test': 117.33781736280622,\n",
       "  'convLSTM2d_filters_layer_1': 8,\n",
       "  'convLSTM2d_kernel_layer_1': 7,\n",
       "  'conv2d_padding_layer_1': 'valid',\n",
       "  'pool2d_size_layer_2': 7,\n",
       "  'learning_rate': 0.0001},\n",
       " 'Arquitectura 7': {'Score': 2973.0986328125,\n",
       "  'Tiempo Scaneo': 830.8654792308807,\n",
       "  'Mape Train': 0.5477234165665507,\n",
       "  'Mape Test': 0.7129874026710077,\n",
       "  'sMape Train': 49.19350162136797,\n",
       "  'sMape Test': 112.12233654667806,\n",
       "  'conv2d_filters_layer_1': 8,\n",
       "  'conv2d_kernel_layer_1': 5,\n",
       "  'conv2d_padding_layer_1': 'valid',\n",
       "  'conv2d_filters_layer_3': 8,\n",
       "  'conv2d_kernel_layer_3': 3,\n",
       "  'conv2d_padding_layer_3': 'valid',\n",
       "  'conv2d_filters_layer_5': 8,\n",
       "  'conv2d_kernel_layer_5': 3,\n",
       "  'conv2d_padding_layer_5': 'same',\n",
       "  'pool_kernel_layer_6': 3,\n",
       "  'lstm_units_layer_7': 64,\n",
       "  'kernel_regularizer_layer_7': 0.0,\n",
       "  'dropout_regularizer_layer_7': 0.8999999999999999,\n",
       "  'dense_units_layer_8': 72,\n",
       "  'dense_layer_8_activation': 'relu',\n",
       "  'learning_rate': 0.0009496618825620572},\n",
       " 'Arquitectura 8': {'Score': 2668.36083984375,\n",
       "  'Tiempo Scaneo': 591.0565452575684,\n",
       "  'Mape Train': 8.501773962042991,\n",
       "  'Mape Test': 2.3953535110834037,\n",
       "  'sMape Train': 92.40066331435595,\n",
       "  'sMape Test': 105.02200829371549,\n",
       "  'conv2d_filters_layer_1': 8,\n",
       "  'conv2d_kernel_layer_1': 7,\n",
       "  'conv2d_padding_layer_1': 'same',\n",
       "  'pool_kernel_layer_2': 3,\n",
       "  'conv2d_filters_layer_3': 8,\n",
       "  'conv2d_kernel_layer_3': 3,\n",
       "  'conv2d_padding_layer_3': 'same',\n",
       "  'pool_kernel_layer_4': 3,\n",
       "  'lstm_units_layer_6': 320,\n",
       "  'kernel_regularizer_layer_6': 0.0375,\n",
       "  'dropout_regularizer_layer_6': 0.72,\n",
       "  'dense_units_layer_7': 72,\n",
       "  'dense_layer_7_activation': 'sigmoid',\n",
       "  'learning_rate': 0.0008836702517620174},\n",
       " 'Arquitectura 9': {'Score': 2040.0,\n",
       "  'Tiempo Scaneo': 790.6637637615204,\n",
       "  'Mape Train': 1.3110373516230744,\n",
       "  'Mape Test': 0.53123166097151,\n",
       "  'sMape Train': 69.8861119212114,\n",
       "  'sMape Test': 77.43374596347155,\n",
       "  'conv2d_filters_layer_1': 8,\n",
       "  'conv2d_kernel_layer_1': 7,\n",
       "  'conv2d_padding_layer_1': 'same',\n",
       "  'pool_kernel_layer_2': 3,\n",
       "  'lstm_units_layer_3': 64,\n",
       "  'kernel_regularizer_layer_4': 0.0,\n",
       "  'dropout_regularizer_layer_4': 0.99,\n",
       "  'dense_units_layer_5': 120,\n",
       "  'dense_layer_5_activation': 'relu',\n",
       "  'learning_rate': 0.00010000000381132293},\n",
       " 'Arquitectura 10': {'Score': 2671.11767578125,\n",
       "  'Tiempo Scaneo': 540.0574786663055,\n",
       "  'Mape Train': 0.676831705932126,\n",
       "  'Mape Test': 0.6647853638570669,\n",
       "  'sMape Train': 52.020945557068664,\n",
       "  'sMape Test': 100.88634150167613,\n",
       "  'conv2d_filters_layer_1': 8,\n",
       "  'conv2d_kernel_layer_1': 3,\n",
       "  'conv2d_padding_layer_1': 'valid',\n",
       "  'conv2d_filters_layer_3': 8,\n",
       "  'conv2d_kernel_layer_3': 3,\n",
       "  'conv2d_padding_layer_3': 'valid',\n",
       "  'conv2d_filters_layer_5': 8,\n",
       "  'conv2d_kernel_layer_5': 3,\n",
       "  'conv2d_padding_layer_5': 'same',\n",
       "  'pool_kernel_layer_6': 5,\n",
       "  'lstm_units_layer_7': 256,\n",
       "  'kernel_regularizer_layer_7': 0.08249999999999999,\n",
       "  'dropout_regularizer_layer_7': 0.8099999999999999,\n",
       "  'learning_rate': 0.003985817960938389},\n",
       " 'Arquitectura 11': {'Score': 3058.970458984375,\n",
       "  'Tiempo Scaneo': 657.5384340286255,\n",
       "  'Mape Train': 0.5253688551255262,\n",
       "  'Mape Test': 0.7222376370836022,\n",
       "  'sMape Train': 48.7790494905247,\n",
       "  'sMape Test': 114.39109969600571,\n",
       "  'conv2d_filters_layer_1': 8,\n",
       "  'conv2d_kernel_layer_1': 3,\n",
       "  'conv2d_padding_layer_1': 'valid',\n",
       "  'pool_kernel_layer_2': 5,\n",
       "  'conv2d_filters_layer_3': 8,\n",
       "  'conv2d_kernel_layer_3': 3,\n",
       "  'conv2d_padding_layer_3': 'valid',\n",
       "  'pool_kernel_layer_4': 3,\n",
       "  'lstm_units_layer_6': 256,\n",
       "  'kernel_regularizer_layer_6': 0.03,\n",
       "  'dropout_regularizer_layer_6': 0.36,\n",
       "  'learning_rate': 0.0002397482640136049},\n",
       " 'Arquitectura 12': {'Score': 1607.894287109375,\n",
       "  'Tiempo Scaneo': 1090.521910905838,\n",
       "  'Mape Train': 4.199707949062598,\n",
       "  'Mape Test': 0.6283296253469837,\n",
       "  'sMape Train': 126.54134032149616,\n",
       "  'sMape Test': 64.87708104238321,\n",
       "  'conv2d_filters_layer_1': 8,\n",
       "  'conv2d_kernel_layer_1': 7,\n",
       "  'conv2d_padding_layer_1': 'valid',\n",
       "  'pool_kernel_layer_2': 3,\n",
       "  'lstm_units_layer_3': 512,\n",
       "  'kernel_regularizer_layer_4': 0.0,\n",
       "  'dropout_regularizer_layer_4': 0.99,\n",
       "  'learning_rate': 0.0001}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arq_best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Proyecto Grados",
   "language": "python",
   "name": "proyecto-grados"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
