{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "import CustomHyperModel\n",
    "import EnergyPricesLibrary as Ep\n",
    "\n",
    "from kerastuner.tuners import BayesianOptimization\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model,scaler_y,trainX,trainY,testX,testY,n_steps_out,len_output_features):\n",
    "    \n",
    "    # make predictions\n",
    "    trainPredict = model.predict(trainX)\n",
    "    trainPredict = trainPredict.reshape(trainPredict.shape[0]*n_steps_out,len_output_features)\n",
    "    testPredict  = model.predict(testX)\n",
    "    testPredict  = testPredict.reshape(testPredict.shape[0]*n_steps_out,len_output_features)\n",
    "    \n",
    "    # invert predictions\n",
    "    trainPredict = scaler_y.inverse_transform(trainPredict)\n",
    "    trainY_ = scaler_y.inverse_transform(trainY.reshape(trainY.shape[0]*n_steps_out,len_output_features))\n",
    "    \n",
    "    testPredict = scaler_y.inverse_transform(testPredict)\n",
    "    testY_ = scaler_y.inverse_transform(testY.reshape(testY.shape[0]*n_steps_out,len_output_features))\n",
    "        \n",
    "    return trainPredict,trainY_,testPredict,testY_\n",
    "\n",
    "def get_metrics(trainY,trainPredict,testY,testPredict):\n",
    "    \n",
    "    trainMAPE  = Ep.MAPE(trainPredict,trainY)\n",
    "    testMAPE  = Ep.MAPE(testPredict,testY)\n",
    "    \n",
    "    return trainMAPE,testMAPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_horaria_path = os.path.join('..','..','dataset','Series','Sabanas','Original','Sabana_Datos_Horaria.xlsx')\n",
    "data_horaria = pd.read_excel(data_horaria_path)\n",
    "data_horaria = data_horaria.set_index('Fecha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "precio_bolsa_path = os.path.join('..','..','dataset','Series','Sabanas','Original','Sabana_Datos_Precio_Bolsa.xlsx')\n",
    "precio_bolsa = pd.read_excel(precio_bolsa_path)\n",
    "precio_bolsa = precio_bolsa.set_index('Fecha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_series = data_horaria.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((176760, 85), (176760, 84), (176760, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df = pd.concat([data_horaria,precio_bolsa],axis=1)\n",
    "full_df.shape,data_horaria.shape,precio_bolsa.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7244, 720, 84), (7244, 24, 1), (91, 720, 84), (91, 24, 1))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = 'All'\n",
    "IndLastMonth = '2020-01-01'\n",
    "n_steps_in = 720\n",
    "n_steps_out=24\n",
    "overlap = 24\n",
    "inputs_columns = nombre_series\n",
    "output_columns = ['$kWh']\n",
    "\n",
    "len_input_features = len(inputs_columns)\n",
    "len_output_features = len(output_columns)\n",
    "\n",
    "trainX, trainY, testX, testY, scaler_x, scaler_y, df2, dataset = Ep.SplitTimeseriesMultipleTimesBackAhead(full_df,\n",
    "                                                                                              day = d, \n",
    "                                                                                              ValData = 'index', \n",
    "                                                                                              TimeAhead = IndLastMonth, \n",
    "                                                                                              n_steps_out= n_steps_out, \n",
    "                                                                                              n_steps_in = n_steps_in, \n",
    "                                                                                              overlap = overlap,\n",
    "                                                                                              input_features=inputs_columns,\n",
    "                                                                                              output_features=output_columns)\n",
    "trainX.shape,trainY.shape,testX.shape,testY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "log_dir = os.path.join('logs','Optimizaci√≥n')\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "callback_tensorboard = tf.keras.callbacks.TensorBoard(log_dir=log_dir,\n",
    "                                                          histogram_freq=2,\n",
    "                                                          write_graph=False,\n",
    "                                                          update_freq='epoch')\n",
    "\"\"\"\n",
    "\n",
    "callback_reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                                          factor=0.1,\n",
    "                                                          min_lr=1e-4,\n",
    "                                                          patience=0,\n",
    "                                                          verbose=1)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                  patience=5,\n",
    "                                                  mode='min')\n",
    "\n",
    "#callbacks = [callback_tensorboard,callback_reduce_lr,early_stopping]\n",
    "callbacks = [callback_reduce_lr,early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (n_steps_in,len_input_features)\n",
    "\n",
    "arquitectura31 = CustomHyperModel.Arquitectura31(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)\n",
    "arquitectura32 = CustomHyperModel.Arquitectura32(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)\n",
    "arquitectura33 = CustomHyperModel.Arquitectura33(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)\n",
    "arquitectura34 = CustomHyperModel.Arquitectura34(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)\n",
    "arquitectura35 = CustomHyperModel.Arquitectura35(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)\n",
    "arquitectura36 = CustomHyperModel.Arquitectura36(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)\n",
    "arquitectura37 = CustomHyperModel.Arquitectura37(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)\n",
    "arquitectura38 = CustomHyperModel.Arquitectura38(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)\n",
    "\n",
    "arquitectura39 = CustomHyperModel.Arquitectura39(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)\n",
    "arquitectura40 = CustomHyperModel.Arquitectura40(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)\n",
    "arquitectura41 = CustomHyperModel.Arquitectura41(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)\n",
    "arquitectura42 = CustomHyperModel.Arquitectura42(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)\n",
    "arquitectura43 = CustomHyperModel.Arquitectura43(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)\n",
    "arquitectura44 = CustomHyperModel.Arquitectura44(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)\n",
    "arquitectura45 = CustomHyperModel.Arquitectura45(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)\n",
    "arquitectura46 = CustomHyperModel.Arquitectura46(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\narq_list = [arquitectura35,arquitectura36,arquitectura37,arquitectura38,\\n            arquitectura39,arquitectura40,arquitectura41,arquitectura42,\\n            arquitectura43,arquitectura44,arquitectura45,arquitectura46]\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arq_list = [arquitectura31,arquitectura32,arquitectura33,arquitectura34,\n",
    "            arquitectura35,arquitectura36,arquitectura37,arquitectura38,\n",
    "            arquitectura39,arquitectura40,arquitectura41,arquitectura42,\n",
    "            arquitectura43,arquitectura44,arquitectura45,arquitectura46]\n",
    "\"\"\"\n",
    "arq_list = [arquitectura35,arquitectura36,arquitectura37,arquitectura38,\n",
    "            arquitectura39,arquitectura40,arquitectura41,arquitectura42,\n",
    "            arquitectura43,arquitectura44,arquitectura45,arquitectura46]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project my_dir\\31\\oracle.json\n"
     ]
    }
   ],
   "source": [
    "arq_idx = 31\n",
    "arq_best_models = dict()\n",
    "\n",
    "for arq in arq_list:\n",
    "    \n",
    "    bayesian_tuner = BayesianOptimization(\n",
    "        arq,\n",
    "        objective='val_mean_absolute_percentage_error',\n",
    "        num_initial_points=1,\n",
    "        max_trials=10,\n",
    "        directory='my_dir',\n",
    "        project_name=str(arq_idx)\n",
    "    )\n",
    "    \n",
    "    # Overview of the task\n",
    "    bayesian_tuner.search_space_summary()\n",
    "    \n",
    "    # Performs the hyperparameter tuning\n",
    "    search_start = time.time()\n",
    "    bayesian_tuner.search(x=trainX,y=trainY,\n",
    "                      epochs=200,\n",
    "                      validation_data=(testX,testY),\n",
    "                      callbacks=callbacks)\n",
    "    search_end = time.time()\n",
    "    elapsed_time = search_end - search_start\n",
    "    \n",
    "    print('Tiempo Total Transcurrido {}'.format(elapsed_time))\n",
    "        \n",
    "    dict_key = 'Arquitectura {}'.format(arq_idx)\n",
    "\n",
    "    arq_best_models[dict_key] = dict()\n",
    "    bs_model = bayesian_tuner.oracle.get_best_trials(1)[0]\n",
    "    \n",
    "    model = bayesian_tuner.get_best_models(num_models=1)[0]\n",
    "    \n",
    "    trainPredict,trainY_true,testPredict,testY_true = make_predictions(model,scaler_y,trainX,trainY,testX,testY,\n",
    "                                                             n_steps_out,len_output_features)\n",
    "    \n",
    "    trainMAPE,testMAPE = get_metrics(trainY_true,trainPredict,testY_true,testPredict)\n",
    "\n",
    "    arq_best_models[dict_key]['Score'] = bs_model.score\n",
    "    arq_best_models[dict_key]['Tiempo Scaneo'] = elapsed_time\n",
    "    arq_best_models[dict_key]['Mape Train'] = trainMAPE\n",
    "    arq_best_models[dict_key]['Mape Test'] = testMAPE\n",
    "\n",
    "    if bs_model.hyperparameters.values:\n",
    "        for hp, value in bs_model.hyperparameters.values.items():\n",
    "            arq_best_models[dict_key][hp] = value\n",
    "    \n",
    "    arq_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arq_best_models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Proyecto Grados",
   "language": "python",
   "name": "proyecto-grados"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
