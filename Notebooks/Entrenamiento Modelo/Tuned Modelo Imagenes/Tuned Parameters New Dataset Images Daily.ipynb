{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import sys\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "sys.path.append('..')\n",
    "import CustomHyperModelImages\n",
    "import EnergyPricesLibrary as Ep\n",
    "\n",
    "from kerastuner.tuners import BayesianOptimization\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model,scaler_y,trainX,trainY,testX,testY,n_steps_out,len_output_features):\n",
    "    \n",
    "    # make predictions\n",
    "    trainPredict = model.predict(trainX)\n",
    "    trainPredict = trainPredict.reshape(trainPredict.shape[0]*n_steps_out,len_output_features)\n",
    "    testPredict  = model.predict(testX)\n",
    "    testPredict  = testPredict.reshape(testPredict.shape[0]*n_steps_out,len_output_features)\n",
    "    \n",
    "    # invert predictions\n",
    "    trainPredict = scaler_y.inverse_transform(trainPredict)\n",
    "    trainY_ = scaler_y.inverse_transform(trainY.reshape(trainY.shape[0]*n_steps_out,len_output_features))\n",
    "    \n",
    "    testPredict = scaler_y.inverse_transform(testPredict)\n",
    "    testY_ = scaler_y.inverse_transform(testY.reshape(testY.shape[0]*n_steps_out,len_output_features))\n",
    "        \n",
    "    return trainPredict,trainY_,testPredict,testY_\n",
    "\n",
    "def get_metrics(trainY,trainPredict,testY,testPredict):\n",
    "    \n",
    "    trainMAPE  = Ep.MAPE(trainPredict,trainY)\n",
    "    testMAPE  = Ep.MAPE(testPredict,testY)\n",
    "    \n",
    "    return trainMAPE,testMAPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ns3_resource = boto3.resource('s3',\\n                             aws_access_key_id='AKIA4NVVYWBFHY2KRSMC',\\n                             aws_secret_access_key='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')\\nbucket = s3_resource.Bucket('colombia-energy-forecast')\\n\\nfor obj in bucket.objects.filter():\\n    if not os.path.exists(os.path.dirname(obj.key)):\\n        os.makedirs(os.path.dirname(obj.key))\\n    bucket.download_file(obj.key, obj.key) # save to same path\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "s3_resource = boto3.resource('s3',\n",
    "                             aws_access_key_id='AKIA4NVVYWBFHY2KRSMC',\n",
    "                             aws_secret_access_key='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')\n",
    "bucket = s3_resource.Bucket('colombia-energy-forecast')\n",
    "\n",
    "for obj in bucket.objects.filter():\n",
    "    if not os.path.exists(os.path.dirname(obj.key)):\n",
    "        os.makedirs(os.path.dirname(obj.key))\n",
    "    bucket.download_file(obj.key, obj.key) # save to same path\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "climatic_images_prcp_dir = os.path.join('dataset','Climatic Images','PRCP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "climatic_images_tavg_dir = os.path.join('dataset','Climatic Images','TAVG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "precio_bolsa_path = os.path.join('dataset','Series','Sabanas','Original','Sabana_Datos_Precio_Bolsa.xlsx')\n",
    "precio_bolsa = pd.read_excel(precio_bolsa_path)\n",
    "precio_bolsa = precio_bolsa.set_index('Fecha')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_fechas = list()\n",
    "lista_rutas = list()\n",
    "for prcp_file,tavg_file in zip(os.listdir(climatic_images_prcp_dir),os.listdir(climatic_images_tavg_dir)):\n",
    "    fecha = prcp_file.split('.')[0]\n",
    "    ruta_prcp = os.path.join(climatic_images_prcp_dir,prcp_file)\n",
    "    ruta_tavg = os.path.join(climatic_images_tavg_dir,tavg_file)\n",
    "    lista_fechas.append(fecha)\n",
    "    lista_rutas.append([ruta_prcp,ruta_tavg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = pd.DataFrame(lista_rutas,index=lista_fechas,columns=['Precipitacion','Temperatura'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TimeSplit_down = '2000-02-01'\n",
    "TimeSplit_middle = '2020-01-01'\n",
    "TimeSplit_top = '2020-03-31'\n",
    "n_steps_out = 24 \n",
    "n_steps_in  = 2\n",
    "overlap = 1\n",
    "\n",
    "output_features = ['$kWh']\n",
    "len_output_features = len(output_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMG_HEIGHT,IMG_WIDTH = 256,256\n",
    "\n",
    "#En caso de que exista problemas de alocación de memoria, descomentar la siguiente línea y comentar la anterior\n",
    "IMG_HEIGHT,IMG_WIDTH = 128,128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainY, testX, testY, scaler_y, dataset_x, dataset_y = Ep.SplitTimeseriesMultipleTimesBackAhead_DifferentTimes_Images(\n",
    "    df_x=dataset_df,\n",
    "    df_y=precio_bolsa,\n",
    "    TimeSplit_down=TimeSplit_down,\n",
    "    TimeSplit_middle=TimeSplit_middle,\n",
    "    TimeSplit_top=TimeSplit_top,\n",
    "    n_steps_out=n_steps_out,\n",
    "    n_steps_in=n_steps_in,\n",
    "    overlap=overlap,\n",
    "    output_features=output_features,\n",
    "    IMG_HEIGHT=IMG_HEIGHT,\n",
    "    IMG_WIDTH=IMG_WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7271, 3, 128, 128, 6), (7271, 24, 1), (91, 3, 128, 128, 6), (91, 24, 1))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape, trainY.shape, testX.shape, testY.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                                          factor=0.1,\n",
    "                                                          min_lr=1e-4,\n",
    "                                                          patience=0,\n",
    "                                                          verbose=1)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                  patience=5,\n",
    "                                                  mode='min')\n",
    "\n",
    "callbacks = [callback_reduce_lr,early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = trainX[0].shape\n",
    "\n",
    "arquitectura1 = CustomHyperModelImages.ArquitecturaI1(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)\n",
    "arquitectura2 = CustomHyperModelImages.ArquitecturaI2(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)\n",
    "arquitectura3 = CustomHyperModelImages.ArquitecturaI3(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)\n",
    "arquitectura4 = CustomHyperModelImages.ArquitecturaI4(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)\n",
    "arquitectura5 = CustomHyperModelImages.ArquitecturaI5(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)\n",
    "arquitectura6 = CustomHyperModelImages.ArquitecturaI6(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)\n",
    "arquitectura7 = CustomHyperModelImages.ArquitecturaI7(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)\n",
    "arquitectura8 = CustomHyperModelImages.ArquitecturaI8(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)\n",
    "arquitectura9 = CustomHyperModelImages.ArquitecturaI9(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)\n",
    "arquitectura10 = CustomHyperModelImages.ArquitecturaI10(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)\n",
    "arquitectura11 = CustomHyperModelImages.ArquitecturaI11(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)\n",
    "arquitectura12 = CustomHyperModelImages.ArquitecturaI12(input_shape=INPUT_SHAPE,n_steps_out=n_steps_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "arq_list = [arquitectura1,arquitectura2,arquitectura3,arquitectura4,\n",
    "            arquitectura5,arquitectura6,arquitectura7,arquitectura8,\n",
    "            arquitectura9,arquitectura10,arquitectura11,arquitectura12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 06m 26s]\n",
      "val_mean_absolute_percentage_error: 63.43312072753906\n",
      "\n",
      "Best val_mean_absolute_percentage_error So Far: 57.278263092041016\n",
      "Total elapsed time: 00h 37m 49s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Tiempo Total Transcurrido 2269.7403433322906\n"
     ]
    }
   ],
   "source": [
    "arq_idx = 1\n",
    "arq_best_models = dict()\n",
    "\n",
    "for arq in arq_list:\n",
    "    \n",
    "    bayesian_tuner = BayesianOptimization(\n",
    "        arq,\n",
    "        objective='val_mean_absolute_percentage_error',\n",
    "        num_initial_points=1,\n",
    "        max_trials=10,\n",
    "        directory=os.path.normpath('C:/my_dir'),\n",
    "        project_name=str(arq_idx)\n",
    "    )\n",
    "    \n",
    "    # Overview of the task\n",
    "    bayesian_tuner.search_space_summary()\n",
    "    \n",
    "    # Performs the hyperparameter tuning\n",
    "    search_start = time.time()\n",
    "    bayesian_tuner.search(x=trainX,y=trainY,\n",
    "                      epochs=200,\n",
    "                      validation_data=(testX,testY),\n",
    "                      callbacks=callbacks)\n",
    "    search_end = time.time()\n",
    "    elapsed_time = search_end - search_start\n",
    "    \n",
    "    print('Tiempo Total Transcurrido {}'.format(elapsed_time))\n",
    "    \n",
    "    dict_key = 'Arquitectura {}'.format(arq_idx)\n",
    "\n",
    "    arq_best_models[dict_key] = dict()\n",
    "    bs_model = bayesian_tuner.oracle.get_best_trials(1)[0]\n",
    "    \n",
    "    model = bayesian_tuner.get_best_models(num_models=1)[0]\n",
    "    \n",
    "    trainPredict,trainY_true,testPredict,testY_true = make_predictions(model,scaler_y,trainX,trainY,testX,testY,\n",
    "                                                             n_steps_out,len_output_features)\n",
    "    \n",
    "    trainMAPE,testMAPE = get_metrics(trainY_true,trainPredict,testY_true,testPredict)\n",
    "\n",
    "    arq_best_models[dict_key]['Score'] = bs_model.score\n",
    "    arq_best_models[dict_key]['Tiempo Scaneo'] = elapsed_time\n",
    "    arq_best_models[dict_key]['Mape Train'] = trainMAPE\n",
    "    arq_best_models[dict_key]['Mape Test'] = testMAPE\n",
    "\n",
    "    if bs_model.hyperparameters.values:\n",
    "        for hp, value in bs_model.hyperparameters.values.items():\n",
    "            arq_best_models[dict_key][hp] = value\n",
    "    \n",
    "    arq_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('BestModels.json', 'w') as outfile:\n",
    "    json.dump(arq_best_models, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Arquitectura 1': {'Score': 35.97036361694336,\n",
       "  'Tiempo Scaneo': 12496.204443454742,\n",
       "  'Mape Train': 2.090536572559958,\n",
       "  'Mape Test': 0.33286573082376814,\n",
       "  'convLSTM2d_filters_layer_1': 8,\n",
       "  'convLSTM2d_kernel_layer_1': 5,\n",
       "  'conv2d_padding_layer_1': 'same',\n",
       "  'convLSTM2d_filters_layer_3': 8,\n",
       "  'convLSTM2d_kernel_layer_3': 3,\n",
       "  'conv2d_padding_layer_3': 'valid',\n",
       "  'convLSTM2d_filters_layer_5': 8,\n",
       "  'convLSTM2d_kernel_layer_5': 5,\n",
       "  'conv2d_padding_layer_5': 'valid',\n",
       "  'pool2d_size_layer_6': 3,\n",
       "  'dense_units_layer_8': 48,\n",
       "  'dense_layer_activation': 'sigmoid',\n",
       "  'learning_rate': 0.0057358015750987625},\n",
       " 'Arquitectura 2': {'Score': 36.516178131103516,\n",
       "  'Tiempo Scaneo': 9744.568314790726,\n",
       "  'Mape Train': 0.6452693665052478,\n",
       "  'Mape Test': 0.3381757872734552,\n",
       "  'convLSTM2d_filters_layer_1': 8,\n",
       "  'convLSTM2d_kernel_layer_1': 7,\n",
       "  'conv2d_padding_layer_1': 'valid',\n",
       "  'pool2d_size_layer_2': 3,\n",
       "  'convLSTM2d_filters_layer_3': 8,\n",
       "  'convLSTM2d_kernel_layer_3': 7,\n",
       "  'conv2d_padding_layer_3': 'valid',\n",
       "  'pool2d_size_layer_4': 5,\n",
       "  'dense_units_layer_6': 24,\n",
       "  'dense_layer_6_activation': 'relu',\n",
       "  'learning_rate': 0.0012180464993437974},\n",
       " 'Arquitectura 3': {'Score': 39.9363899230957,\n",
       "  'Tiempo Scaneo': 6486.245057582855,\n",
       "  'Mape Train': 0.5906516975314957,\n",
       "  'Mape Test': 0.37105775483977144,\n",
       "  'convLSTM2d_filters_layer_1': 8,\n",
       "  'convLSTM2d_kernel_layer_1': 5,\n",
       "  'conv2d_padding_layer_1': 'valid',\n",
       "  'pool2d_size_layer_2': 5,\n",
       "  'dense_units_layer_4': 96,\n",
       "  'dense_layer_4_activation': 'relu',\n",
       "  'learning_rate': 0.0008802728712752222},\n",
       " 'Arquitectura 4': {'Score': 36.502540588378906,\n",
       "  'Tiempo Scaneo': 10800.107825279236,\n",
       "  'Mape Train': 0.6797565962391944,\n",
       "  'Mape Test': 0.3380913992039091,\n",
       "  'convLSTM2d_filters_layer_1': 8,\n",
       "  'convLSTM2d_kernel_layer_1': 5,\n",
       "  'conv2d_padding_layer_1': 'same',\n",
       "  'convLSTM2d_filters_layer_3': 8,\n",
       "  'convLSTM2d_kernel_layer_3': 3,\n",
       "  'conv2d_padding_layer_3': 'same',\n",
       "  'convLSTM2d_filters_layer_5': 8,\n",
       "  'convLSTM2d_kernel_layer_5': 5,\n",
       "  'conv2d_padding_layer_5': 'valid',\n",
       "  'pool2d_size_layer_6': 3,\n",
       "  'learning_rate': 0.0024833141521926165},\n",
       " 'Arquitectura 5': {'Score': 34.75155258178711,\n",
       "  'Tiempo Scaneo': 7875.716263532639,\n",
       "  'Mape Train': 0.8010157991952083,\n",
       "  'Mape Test': 0.3207761950253796,\n",
       "  'convLSTM2d_filters_layer_1': 8,\n",
       "  'convLSTM2d_kernel_layer_1': 7,\n",
       "  'conv2d_padding_layer_1': 'valid',\n",
       "  'pool2d_size_layer_2': 5,\n",
       "  'convLSTM2d_filters_layer_3': 8,\n",
       "  'convLSTM2d_kernel_layer_3': 3,\n",
       "  'conv2d_padding_layer_3': 'same',\n",
       "  'pool2d_size_layer_4': 3,\n",
       "  'learning_rate': 0.008464442571538682},\n",
       " 'Arquitectura 6': {'Score': 36.770572662353516,\n",
       "  'Tiempo Scaneo': 7607.600725412369,\n",
       "  'Mape Train': 0.6503952759232818,\n",
       "  'Mape Test': 0.3407172473488282,\n",
       "  'convLSTM2d_filters_layer_1': 8,\n",
       "  'convLSTM2d_kernel_layer_1': 7,\n",
       "  'conv2d_padding_layer_1': 'same',\n",
       "  'pool2d_size_layer_2': 5,\n",
       "  'learning_rate': 0.00032502082475009935},\n",
       " 'Arquitectura 7': {'Score': 53.82461166381836,\n",
       "  'Tiempo Scaneo': 1752.9782643318176,\n",
       "  'Mape Train': 1.2593679877301918,\n",
       "  'Mape Test': 0.503446513386109,\n",
       "  'conv2d_filters_layer_1': 8,\n",
       "  'conv2d_kernel_layer_1': 3,\n",
       "  'conv2d_padding_layer_1': 'same',\n",
       "  'conv2d_filters_layer_3': 8,\n",
       "  'conv2d_kernel_layer_3': 5,\n",
       "  'conv2d_padding_layer_3': 'same',\n",
       "  'conv2d_filters_layer_5': 8,\n",
       "  'conv2d_kernel_layer_5': 3,\n",
       "  'conv2d_padding_layer_5': 'valid',\n",
       "  'pool_kernel_layer_6': 3,\n",
       "  'lstm_units_layer_7': 64,\n",
       "  'kernel_regularizer_layer_7': 0.09,\n",
       "  'dropout_regularizer_layer_7': 0.54,\n",
       "  'dense_units_layer_8': 72,\n",
       "  'dense_layer_8_activation': 'sigmoid',\n",
       "  'learning_rate': 0.007913979537147965},\n",
       " 'Arquitectura 8': {'Score': 33.84981155395508,\n",
       "  'Tiempo Scaneo': 1553.110607624054,\n",
       "  'Mape Train': 3.2068420244753226,\n",
       "  'Mape Test': 0.30479395803460774,\n",
       "  'conv2d_filters_layer_1': 8,\n",
       "  'conv2d_kernel_layer_1': 3,\n",
       "  'conv2d_padding_layer_1': 'valid',\n",
       "  'pool_kernel_layer_2': 5,\n",
       "  'conv2d_filters_layer_3': 8,\n",
       "  'conv2d_kernel_layer_3': 5,\n",
       "  'conv2d_padding_layer_3': 'valid',\n",
       "  'pool_kernel_layer_4': 3,\n",
       "  'lstm_units_layer_6': 64,\n",
       "  'kernel_regularizer_layer_6': 0.105,\n",
       "  'dropout_regularizer_layer_6': 0.27,\n",
       "  'dense_units_layer_7': 96,\n",
       "  'dense_layer_7_activation': 'sigmoid',\n",
       "  'learning_rate': 0.01},\n",
       " 'Arquitectura 9': {'Score': 44.3486213684082,\n",
       "  'Tiempo Scaneo': 2371.290080308914,\n",
       "  'Mape Train': 0.9601965082322999,\n",
       "  'Mape Test': 0.4130083618012623,\n",
       "  'conv2d_filters_layer_1': 8,\n",
       "  'conv2d_kernel_layer_1': 5,\n",
       "  'conv2d_padding_layer_1': 'same',\n",
       "  'pool_kernel_layer_2': 5,\n",
       "  'lstm_units_layer_3': 512,\n",
       "  'kernel_regularizer_layer_4': 0.0,\n",
       "  'dropout_regularizer_layer_4': 0.18,\n",
       "  'dense_units_layer_5': 96,\n",
       "  'dense_layer_5_activation': 'sigmoid',\n",
       "  'learning_rate': 0.01},\n",
       " 'Arquitectura 10': {'Score': 37.841156005859375,\n",
       "  'Tiempo Scaneo': 1609.6612331867218,\n",
       "  'Mape Train': 0.7989749928577687,\n",
       "  'Mape Test': 0.35098210461606943,\n",
       "  'conv2d_filters_layer_1': 8,\n",
       "  'conv2d_kernel_layer_1': 5,\n",
       "  'conv2d_padding_layer_1': 'same',\n",
       "  'conv2d_filters_layer_3': 8,\n",
       "  'conv2d_kernel_layer_3': 3,\n",
       "  'conv2d_padding_layer_3': 'valid',\n",
       "  'conv2d_filters_layer_5': 8,\n",
       "  'conv2d_kernel_layer_5': 3,\n",
       "  'conv2d_padding_layer_5': 'valid',\n",
       "  'pool_kernel_layer_6': 3,\n",
       "  'lstm_units_layer_7': 512,\n",
       "  'kernel_regularizer_layer_7': 0.0,\n",
       "  'dropout_regularizer_layer_7': 0.0,\n",
       "  'learning_rate': 0.0001},\n",
       " 'Arquitectura 11': {'Score': 61.665199279785156,\n",
       "  'Tiempo Scaneo': 1907.996092557907,\n",
       "  'Mape Train': 0.9627698419210584,\n",
       "  'Mape Test': 0.5778228559586883,\n",
       "  'conv2d_filters_layer_1': 8,\n",
       "  'conv2d_kernel_layer_1': 7,\n",
       "  'conv2d_padding_layer_1': 'same',\n",
       "  'pool_kernel_layer_2': 5,\n",
       "  'conv2d_filters_layer_3': 8,\n",
       "  'conv2d_kernel_layer_3': 7,\n",
       "  'conv2d_padding_layer_3': 'valid',\n",
       "  'pool_kernel_layer_4': 5,\n",
       "  'lstm_units_layer_6': 384,\n",
       "  'kernel_regularizer_layer_6': 0.0975,\n",
       "  'dropout_regularizer_layer_6': 0.27,\n",
       "  'learning_rate': 0.0004412704801355342},\n",
       " 'Arquitectura 12': {'Score': 57.278263092041016,\n",
       "  'Tiempo Scaneo': 2269.7403433322906,\n",
       "  'Mape Train': 1.180164539240549,\n",
       "  'Mape Test': 0.5356033282588937,\n",
       "  'conv2d_filters_layer_1': 8,\n",
       "  'conv2d_kernel_layer_1': 3,\n",
       "  'conv2d_padding_layer_1': 'same',\n",
       "  'pool_kernel_layer_2': 5,\n",
       "  'lstm_units_layer_3': 512,\n",
       "  'kernel_regularizer_layer_4': 0.06,\n",
       "  'dropout_regularizer_layer_4': 0.36,\n",
       "  'learning_rate': 0.00977060690028708}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arq_best_models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Proyecto Grados",
   "language": "python",
   "name": "proyecto-grados"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
