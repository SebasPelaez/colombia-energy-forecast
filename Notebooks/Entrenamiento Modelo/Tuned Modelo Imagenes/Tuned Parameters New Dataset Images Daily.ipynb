{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "import CustomHyperModel\n",
    "import EnergyPricesLibrary as Ep\n",
    "\n",
    "from kerastuner.tuners import BayesianOptimization\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_resource = boto3.resource('s3',\n",
    "                             aws_access_key_id='AKIA4NVVYWBFHY2KRSMC',\n",
    "                             aws_secret_access_key='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')\n",
    "bucket = s3_resource.Bucket('colombia-energy-forecast')\n",
    "\n",
    "for obj in bucket.objects.filter():\n",
    "    if not os.path.exists(os.path.dirname(obj.key)):\n",
    "        os.makedirs(os.path.dirname(obj.key))\n",
    "    bucket.download_file(obj.key, obj.key) # save to same path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "climatic_images_prcp_dir = os.path.join('dataset','Climatic Images','PRCP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "climatic_images_tavg_dir = os.path.join('dataset','Climatic Images','TAVG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "precio_bolsa_path = os.path.join('dataset','Series','Sabanas','Original','Sabana_Datos_Precio_Bolsa.xlsx')\n",
    "precio_bolsa = pd.read_excel(precio_bolsa_path)\n",
    "precio_bolsa = precio_bolsa.set_index('Fecha')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_fechas = list()\n",
    "lista_rutas = list()\n",
    "for prcp_file,tavg_file in zip(os.listdir(climatic_images_prcp_dir),os.listdir(climatic_images_tavg_dir)):\n",
    "    fecha = prcp_file.split('.')[0]\n",
    "    ruta_prcp = os.path.join(climatic_images_prcp_dir,prcp_file)\n",
    "    ruta_tavg = os.path.join(climatic_images_tavg_dir,tavg_file)\n",
    "    lista_fechas.append(fecha)\n",
    "    lista_rutas.append([ruta_prcp,ruta_tavg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = pd.DataFrame(lista_rutas,index=lista_fechas,columns=['Precipitacion','Temperatura'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TimeSplit_down = '2000-02-01'\n",
    "TimeSplit_middle = '2020-01-01'\n",
    "TimeSplit_top = '2020-03-31'\n",
    "n_steps_out = 24 \n",
    "n_steps_in  = 3\n",
    "overlap = 2\n",
    "\n",
    "output_features = ['$kWh']\n",
    "len_output_features = len(output_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMG_HEIGHT,IMG_WIDTH = 256,256\n",
    "\n",
    "#En caso de que exista problemas de alocación de memoria, descomentar la siguiente línea y comentar la anterior\n",
    "IMG_HEIGHT,IMG_WIDTH = 128,128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainY, testX, testY, scaler_y, dataset_x, dataset_y = Ep.SplitTimeseriesMultipleTimesBackAhead_DifferentTimes_Images(\n",
    "    df_x=dataset_df,\n",
    "    df_y=precio_bolsa,\n",
    "    TimeSplit_down=TimeSplit_down,\n",
    "    TimeSplit_middle=TimeSplit_middle,\n",
    "    TimeSplit_top=TimeSplit_top,\n",
    "    n_steps_out=n_steps_out,\n",
    "    n_steps_in=n_steps_in,\n",
    "    overlap=overlap,\n",
    "    output_features=output_features,\n",
    "    IMG_HEIGHT=IMG_HEIGHT,\n",
    "    IMG_WIDTH=IMG_WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3636, 3, 128, 128, 6), (3636, 24, 1), (46, 3, 128, 128, 6), (46, 24, 1))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape, trainY.shape, testX.shape, testY.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                                          factor=0.1,\n",
    "                                                          min_lr=1e-4,\n",
    "                                                          patience=0,\n",
    "                                                          verbose=1)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                  patience=5,\n",
    "                                                  mode='min')\n",
    "\n",
    "callbacks = [callback_reduce_lr,early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquitectura25 = CustomHyperModel.Arquitectura25(input_shape=trainX[0].shape,output_units=len_output_features,n_steps_out=n_steps_out)\n",
    "arquitectura26 = CustomHyperModel.Arquitectura26(input_shape=trainX[0].shape,output_units=len_output_features,n_steps_out=n_steps_out)\n",
    "arquitectura27 = CustomHyperModel.Arquitectura27(input_shape=trainX[0].shape,output_units=len_output_features,n_steps_out=n_steps_out)\n",
    "arquitectura28 = CustomHyperModel.Arquitectura28(input_shape=trainX[0].shape,output_units=len_output_features,n_steps_out=n_steps_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "arq_list = [arquitectura25,arquitectura26,arquitectura27,arquitectura28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 15 Complete [00h 03m 05s]\n",
      "val_mean_absolute_percentage_error: 49.1245002746582\n",
      "\n",
      "Best val_mean_absolute_percentage_error So Far: 43.9294548034668\n",
      "Total elapsed time: 00h 54m 46s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Tiempo Total Transcurrido 3286.242907524109\n"
     ]
    }
   ],
   "source": [
    "arq_idx = 25\n",
    "arq_best_models = dict()\n",
    "\n",
    "for arq in arq_list:\n",
    "    \n",
    "    bayesian_tuner = BayesianOptimization(\n",
    "        arq,\n",
    "        objective='val_mean_absolute_percentage_error',\n",
    "        num_initial_points=1,\n",
    "        max_trials=15,\n",
    "        directory=os.path.normpath('C:/my_dir'),\n",
    "        project_name=str(arq_idx)\n",
    "    )\n",
    "    \n",
    "    # Overview of the task\n",
    "    bayesian_tuner.search_space_summary()\n",
    "    \n",
    "    # Performs the hyperparameter tuning\n",
    "    search_start = time.time()\n",
    "    bayesian_tuner.search(x=trainX,y=trainY,\n",
    "                      epochs=200,\n",
    "                      validation_data=(testX,testY),\n",
    "                      callbacks=callbacks)\n",
    "    search_end = time.time()\n",
    "    elapsed_time = search_end - search_start\n",
    "    \n",
    "    print('Tiempo Total Transcurrido {}'.format(elapsed_time))\n",
    "    \n",
    "    # Show a summary of the search\n",
    "    #bayesian_tuner.results_summary()\n",
    "    \n",
    "    dict_key = 'Arquitectura {}'.format(arq_idx)\n",
    "\n",
    "    arq_best_models[dict_key] = dict()\n",
    "    bs_model = bayesian_tuner.oracle.get_best_trials(1)[0]\n",
    "\n",
    "    arq_best_models[dict_key]['Score'] = bs_model.score\n",
    "    arq_best_models[dict_key]['Tiempo Scaneo'] = elapsed_time\n",
    "\n",
    "    if bs_model.hyperparameters.values:\n",
    "        for hp, value in bs_model.hyperparameters.values.items():\n",
    "            arq_best_models[dict_key][hp] = value\n",
    "    \n",
    "    arq_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('BestModels.json', 'w') as outfile:\n",
    "    json.dump(arq_best_models, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Arquitectura 25': {'Score': 29.02768325805664,\n",
       "  'Tiempo Scaneo': 2016.7844245433807,\n",
       "  'conv2d_filters_layer_1': 64,\n",
       "  'conv2d_kernel_layer_1': 3,\n",
       "  'conv2d_padding_layer_1': 'same',\n",
       "  'conv2d_filters_layer_3': 64,\n",
       "  'conv2d_kernel_layer_3': 5,\n",
       "  'conv2d_padding_layer_3': 'valid',\n",
       "  'conv2d_filters_layer_5': 64,\n",
       "  'conv2d_kernel_layer_5': 3,\n",
       "  'conv2d_padding_layer_5': 'same',\n",
       "  'lstm_units_layer_7': 64,\n",
       "  'kernel_regularizer_layer_7': 0.0,\n",
       "  'dropout_regularizer_layer_7': 0.0,\n",
       "  'learning_rate': 0.0001},\n",
       " 'Arquitectura 26': {'Score': 48.08729553222656,\n",
       "  'Tiempo Scaneo': 3316.5392682552338,\n",
       "  'conv2d_filters_layer_1': 48,\n",
       "  'conv2d_kernel_layer_1': 3,\n",
       "  'conv2d_padding_layer_1': 'valid',\n",
       "  'conv2d_filters_layer_3': 24,\n",
       "  'conv2d_kernel_layer_3': 3,\n",
       "  'conv2d_padding_layer_3': 'valid',\n",
       "  'conv2d_filters_layer_5': 60,\n",
       "  'conv2d_kernel_layer_5': 3,\n",
       "  'conv2d_padding_layer_5': 'same',\n",
       "  'lstm_units_layer_7': 256,\n",
       "  'kernel_regularizer_layer_7': 0.09,\n",
       "  'dropout_regularizer_layer_7': 0.27,\n",
       "  'learning_rate': 0.00014359055128164333},\n",
       " 'Arquitectura 27': {'Score': 25.64593505859375,\n",
       "  'Tiempo Scaneo': 2750.4906005859375,\n",
       "  'conv2d_filters_layer_1': 52,\n",
       "  'conv2d_kernel_layer_1': 5,\n",
       "  'conv2d_padding_layer_1': 'valid',\n",
       "  'pool2d_size_layer_2': 3,\n",
       "  'conv2d_filters_layer_3': 8,\n",
       "  'conv2d_kernel_layer_3': 5,\n",
       "  'conv2d_padding_layer_3': 'same',\n",
       "  'pool2d_size_layer_4': 6,\n",
       "  'lstm_units_layer_5': 384,\n",
       "  'kernel_regularizer_layer_5': 0.09,\n",
       "  'dropout_regularizer_layer_5': 0.09,\n",
       "  'learning_rate': 0.009943340592155157},\n",
       " 'Arquitectura 28': {'Score': 43.9294548034668,\n",
       "  'Tiempo Scaneo': 3286.242907524109,\n",
       "  'conv2d_filters_layer_1': 12,\n",
       "  'conv2d_kernel_layer_1': 7,\n",
       "  'conv2d_padding_layer_1': 'same',\n",
       "  'pool2d_size_layer_2': 7,\n",
       "  'conv2d_filters_layer_3': 60,\n",
       "  'conv2d_kernel_layer_3': 7,\n",
       "  'conv2d_padding_layer_3': 'valid',\n",
       "  'pool2d_size_layer_4': 5,\n",
       "  'lstm_units_layer_7': 512,\n",
       "  'kernel_regularizer_layer_7': 0.09,\n",
       "  'dropout_regularizer_layer_7': 0.44999999999999996,\n",
       "  'learning_rate': 0.00012180019936545399}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arq_best_models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Proyecto Grados",
   "language": "python",
   "name": "proyecto-grados"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
