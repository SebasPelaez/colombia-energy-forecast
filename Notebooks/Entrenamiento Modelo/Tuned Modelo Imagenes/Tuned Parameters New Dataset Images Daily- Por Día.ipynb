{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import sys\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "sys.path.append('..')\n",
    "import CustomHyperModelImages\n",
    "import EnergyPricesLibrary as Ep\n",
    "\n",
    "from kerastuner.tuners import BayesianOptimization\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model,scaler_y,trainX,trainY,testX,testY,n_steps_out,len_output_features):\n",
    "    \n",
    "    # make predictions\n",
    "    trainPredict = model.predict(trainX)\n",
    "    trainPredict = trainPredict.reshape(trainPredict.shape[0]*n_steps_out,len_output_features)\n",
    "    testPredict  = model.predict(testX)\n",
    "    testPredict  = testPredict.reshape(testPredict.shape[0]*n_steps_out,len_output_features)\n",
    "    \n",
    "    # invert predictions\n",
    "    trainPredict = scaler_y.inverse_transform(trainPredict)\n",
    "    trainY_ = scaler_y.inverse_transform(trainY.reshape(trainY.shape[0]*n_steps_out,len_output_features))\n",
    "    \n",
    "    testPredict = scaler_y.inverse_transform(testPredict)\n",
    "    testY_ = scaler_y.inverse_transform(testY.reshape(testY.shape[0]*n_steps_out,len_output_features))\n",
    "        \n",
    "    return trainPredict,trainY_,testPredict,testY_\n",
    "\n",
    "def get_metrics(trainY,trainPredict,testY,testPredict):\n",
    "    \n",
    "    trainMAPE  = Ep.MAPE(trainPredict,trainY)\n",
    "    testMAPE  = Ep.MAPE(testPredict,testY)\n",
    "    \n",
    "    train_sMAPE  = Ep.sMAPE(trainY,trainPredict)\n",
    "    test_sMAPE  = Ep.sMAPE(testY,testPredict)\n",
    "    \n",
    "    return trainMAPE,testMAPE,train_sMAPE,test_sMAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_images(lista_rutas,lista_fechas,n_steps_in,overlap,day,\n",
    "                       start_date_train,start_date_val,start_date_test,end_date_test,\n",
    "                       n_steps_out,output_columns):\n",
    "    \n",
    "    dataset_df = pd.DataFrame(lista_rutas,index=lista_fechas,columns=['Precipitacion','Temperatura'])\n",
    "    inputs_columns=dataset_df.columns.values\n",
    "    \n",
    "    dataset_df['day_of_week'] = dataset_df.index.day_name()\n",
    "    \n",
    "    len_output_features = len(output_columns)\n",
    "\n",
    "    IMG_HEIGHT,IMG_WIDTH = 128,128\n",
    "\n",
    "    results = Ep.SplitTimeseriesMultipleTimesBackAhead_DifferentTimes_Images(df_x=dataset_df,df_y=precio_bolsa,\n",
    "                                                                             day=day,\n",
    "                                                                             start_date_train=start_date_train,\n",
    "                                                                             start_date_val=start_date_val,\n",
    "                                                                             start_date_test=start_date_test,\n",
    "                                                                             end_date_test=end_date_test,\n",
    "                                                                             n_steps_out=n_steps_out,\n",
    "                                                                             n_steps_in=n_steps_in,overlap=overlap,\n",
    "                                                                             output_features=output_columns,\n",
    "                                                                             input_features=inputs_columns,\n",
    "                                                                             IMG_HEIGHT=IMG_HEIGHT,IMG_WIDTH=IMG_WIDTH)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_callbacks():\n",
    "    \n",
    "    callback_reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                                              factor=0.1,\n",
    "                                                              min_lr=1e-5,\n",
    "                                                              patience=5,\n",
    "                                                              verbose=1)\n",
    "\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                      patience=10,\n",
    "                                                      mode='min')\n",
    "\n",
    "    callbacks = [callback_reduce_lr,early_stopping]\n",
    "    \n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_arquitecturas(input_shape,n_steps_out):\n",
    "\n",
    "    arquitectura13 = CustomHyperModelImages.ArquitecturaI13(input_shape=input_shape,n_steps_out=n_steps_out)\n",
    "    arquitectura14 = CustomHyperModelImages.ArquitecturaI14(input_shape=input_shape,n_steps_out=n_steps_out)\n",
    "\n",
    "    arq_list = [arquitectura13,arquitectura14]\n",
    "    \n",
    "    return arq_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "climatic_images_prcp_dir = os.path.join('..','..','..','dataset','Climatic Images','PRCP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "climatic_images_tavg_dir = os.path.join('..','..','..','dataset','Climatic Images','TAVG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "precio_bolsa_path = os.path.join('..','..','..','dataset','Series','Sabanas','Original','Sabana_Datos_Precio_Bolsa.xlsx')\n",
    "precio_bolsa = pd.read_excel(precio_bolsa_path)\n",
    "precio_bolsa = precio_bolsa.set_index('Fecha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "precio_bolsa['day_of_week'] = precio_bolsa.index.day_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_fechas = list()\n",
    "lista_rutas = list()\n",
    "for prcp_file,tavg_file in zip(os.listdir(climatic_images_prcp_dir),os.listdir(climatic_images_tavg_dir)):\n",
    "    fecha = prcp_file.split('.')[0]\n",
    "    ruta_prcp = os.path.join(climatic_images_prcp_dir,prcp_file)\n",
    "    ruta_tavg = os.path.join(climatic_images_tavg_dir,tavg_file)\n",
    "    lista_fechas.append(pd.to_datetime(fecha))\n",
    "    lista_rutas.append([ruta_prcp,ruta_tavg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Days = np.array(['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'])\n",
    "\n",
    "start_date_train = '2000-02-01'\n",
    "start_date_val = '2020-01-01'\n",
    "start_date_test = '2020-04-01'\n",
    "end_date_test = '2020-05-01'\n",
    "n_steps_out=24\n",
    "output_columns = ['$kWh']\n",
    "len_output_features = len(output_columns)\n",
    "n_steps_in = 2\n",
    "overlap = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 18s]\n",
      "val_loss: 3651.11279296875\n",
      "\n",
      "Best val_loss So Far: 736.3565673828125\n",
      "Total elapsed time: 00h 15m 03s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "dict_days_test = dict()\n",
    "\n",
    "for j,d in enumerate(Days):\n",
    "    \n",
    "    result_from_images = get_dataset_images(lista_rutas,lista_fechas,n_steps_in=n_steps_in,overlap=overlap,day=d,\n",
    "                                            start_date_train=start_date_train,start_date_val=start_date_val,\n",
    "                                            start_date_test=start_date_test,end_date_test=end_date_test,\n",
    "                                            n_steps_out=n_steps_out,output_columns=output_columns)\n",
    "    \n",
    "    trainX_I,trainY_I,valX_I,valY_I,testX_I,testY_I,scaler_y_I,dataset_x_I,dataset_y_I = result_from_images\n",
    "    \n",
    "    images_input_shape = trainX_I[0].shape\n",
    "    callbacks = crear_callbacks()\n",
    "    arq_list = generar_arquitecturas(images_input_shape,n_steps_out)\n",
    "    \n",
    "    arq_idx = 13\n",
    "    arq_best_models = dict()\n",
    "\n",
    "    for arq in arq_list:\n",
    "        \n",
    "        project_name = '{}-Arquitectura{}'.format(d,arq_idx)\n",
    "\n",
    "        bayesian_tuner = BayesianOptimization(\n",
    "            arq,\n",
    "            objective='val_loss',\n",
    "            num_initial_points=1,\n",
    "            max_trials=10,\n",
    "            directory=os.path.normpath('C:/my_dir'),\n",
    "            project_name=project_name\n",
    "        )\n",
    "\n",
    "        # Overview of the task\n",
    "        bayesian_tuner.search_space_summary()\n",
    "\n",
    "        # Performs the hyperparameter tuning\n",
    "        search_start = time.time()\n",
    "        bayesian_tuner.search(x=trainX_I,y=trainY_I,\n",
    "                          epochs=200,\n",
    "                          validation_data=(valX_I,valY_I),\n",
    "                          callbacks=callbacks)\n",
    "        search_end = time.time()\n",
    "        elapsed_time = search_end - search_start\n",
    "\n",
    "        dict_key = project_name\n",
    "\n",
    "        arq_best_models[dict_key] = dict()\n",
    "        bs_model = bayesian_tuner.oracle.get_best_trials(1)[0]\n",
    "\n",
    "        model = bayesian_tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "        trainPredict,trainY_true,testPredict,testY_true = make_predictions(model,scaler_y_I,trainX_I,trainY_I,valX_I,valY_I,\n",
    "                                                                           n_steps_out,len_output_features)\n",
    "\n",
    "        trainMAPE,testMAPE,train_sMAPE,test_sMAPE = get_metrics(trainY_true,trainPredict,testY_true,testPredict)\n",
    "\n",
    "        arq_best_models[dict_key]['Score'] = bs_model.score\n",
    "        arq_best_models[dict_key]['Tiempo Scaneo'] = elapsed_time\n",
    "        arq_best_models[dict_key]['Mape Train'] = trainMAPE\n",
    "        arq_best_models[dict_key]['Mape Test'] = testMAPE\n",
    "        arq_best_models[dict_key]['sMape Train'] = train_sMAPE\n",
    "        arq_best_models[dict_key]['sMape Test'] = test_sMAPE\n",
    "\n",
    "        if bs_model.hyperparameters.values:\n",
    "            for hp, value in bs_model.hyperparameters.values.items():\n",
    "                arq_best_models[dict_key][hp] = value\n",
    "\n",
    "        arq_idx += 1\n",
    "        \n",
    "    with open('{}-BestModels.json'.format(d), 'w') as outfile:\n",
    "        json.dump(arq_best_models, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Proyecto Grados",
   "language": "python",
   "name": "proyecto-grados"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
